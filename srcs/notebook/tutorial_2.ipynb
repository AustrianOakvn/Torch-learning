{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9b7bfb3-f6dc-4047-84b4-0ad1ba4627d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a80b9",
   "metadata": {},
   "source": [
    "### Tensor operations\n",
    "tensor.new() \\\n",
    "tensor.view() \\\n",
    "tensor.permute() \\\n",
    "tensor.transpose() \\\n",
    "tensor.unsqueeze() \\\n",
    "tensor.expand_as() \\\n",
    "tensor.le() \\\n",
    "tensor.gt() \\\n",
    "tensor.contiguous()\n",
    "\n",
    "### Torch function\n",
    "torch.cat()\n",
    "torch.numel()\n",
    "\n",
    "\n",
    "### Torch loss function\n",
    "torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1672fa60",
   "metadata": {},
   "source": [
    "#### torch operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ebc05df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n",
      "torch.int16\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor vs torch.Tensor\n",
    "# torch.tensor infer dtype automatically\n",
    "# torch.Tensor returns torch.FloatTensor\n",
    "\n",
    "example = [1, 2, 3, 4, 5]\n",
    "example_t1 = torch.Tensor(example)\n",
    "example_t2 = torch.tensor(example)\n",
    "print(example_t1.dtype)\n",
    "print(example_t2.dtype)\n",
    "\n",
    "# You can also change the type of data with torch.tensor easily\n",
    "example_t2 = example_t2.type(torch.short)\n",
    "print(example_t2.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee1d38",
   "metadata": {},
   "source": [
    "#### torch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0afbd7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "r_tensor = torch.rand((3, 3))\n",
    "# numel returns number of elements inside a tensor\n",
    "print(torch.numel(r_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272cae52",
   "metadata": {},
   "source": [
    "#### Understand CrossEntropyLoss\n",
    "Step 1: Convert the label into one hot vector \\\n",
    "Step 2: Calculate the prob using softmax function \\\n",
    "Step 3: Calculate cross entropy by (-1/N)*sum(gt_y * log(y_pred)) where gt_y is the groundtruth (label) vector and y_pred is the prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6f06580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.  0.8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07438118377140324"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### My implementation\n",
    "y = np.array([0, 0, 1])\n",
    "pre_y = np.array([0.1, 0.1, 0.8])\n",
    "\n",
    "print(y*pre_y)\n",
    "\n",
    "def softmax(input):\n",
    "    return np.exp(input)/np.sum(np.exp(input), axis=0)\n",
    "\n",
    "def cross_entropy(gt_dist, pre_dist):\n",
    "    # In this log is actually ln\n",
    "    loss = -1*np.sum(gt_dist*np.log(pre_dist))\n",
    "    return loss/gt_dist.shape[0]\n",
    "\n",
    "cross_entropy(y, pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b54d7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.8329)\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# CrossEntropyLoss from Pytorch already implement softmax\n",
    "# so don't need that layer\n",
    "prediction = [[1.0, 2.2, 5.7, 3.1, 0.3, 4.5, 3.6]]\n",
    "ground_truth = [4]\n",
    "# ground_truth = [2]\n",
    "output = loss(torch.tensor(prediction), torch.tensor(ground_truth))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6092869a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3850767910480499\n",
      "2.4398019313812256\n"
     ]
    }
   ],
   "source": [
    "y=torch.tensor([2])\n",
    " \n",
    "y_pre_good=torch.tensor([[1.0,1.1,2.5]])\n",
    "y_pre_bed=torch.tensor([[3.2,0.2,0.9]])\n",
    " \n",
    " \n",
    "l1=loss(y_pre_good,y)\n",
    "l2=loss(y_pre_bed,y)\n",
    " \n",
    "print(l1.item()) #0.3850\n",
    "print(l2.item()) #2.4398"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f7b350",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
